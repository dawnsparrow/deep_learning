{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "# from sklearn.metrics import log_loss\n",
    "from numpy.random import permutation\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "np.random.seed(2016)\n",
    "use_cache = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以RGB形式获取一张图像并预处理（减去RGB均值）\n",
    "def get_im(path, img_rows=224, img_cols=224):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    mean_pixel = [113.68, 116.799, 103.939]\n",
    "    \n",
    "    for c in range(3):\n",
    "        resized[:, :, c] = resized[:, :, c] - mean_pixel[c]\n",
    "\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从driver_imgs_list.csv获取（图像文件名-司机id）字典\n",
    "def get_driver_data():\n",
    "    dr = dict()\n",
    "    path = os.path.join('.', 'driver_imgs_list.csv')\n",
    "    print('Read drivers data')\n",
    "    f = open(path, 'r')\n",
    "    line = f.readline()\n",
    "    while (1):\n",
    "        line = f.readline()\n",
    "        if line == '':\n",
    "            break\n",
    "        arr = line.strip().split(',')\n",
    "        dr[arr[2]] = arr[0]\n",
    "    f.close()\n",
    "    return dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以ndarray形式加载训练集,并对标签进行独热编码\n",
    "def load_train(img_rows=224, img_cols=224):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    driver_id = []\n",
    "\n",
    "    driver_data = get_driver_data()\n",
    "\n",
    "    print('Read train images')\n",
    "    for j in range(10):\n",
    "        print('Load folder c{}'.format(j))\n",
    "        path = os.path.join('.', 'train', 'c' + str(j), '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = get_im(fl, img_rows, img_cols)\n",
    "            X_train.append(img)\n",
    "            y_train.append(j)\n",
    "            driver_id.append(driver_data[flbase])\n",
    "    \n",
    "    one_hot_encoder = preprocessing.OneHotEncoder(n_values=10)\n",
    "    y_train = one_hot_encoder.fit_transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "    unique_drivers = sorted(list(set(driver_id)))\n",
    "    print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "    print(unique_drivers)\n",
    "    return np.array(X_train, dtype='float32'), np.array(y_train, dtype='float32'), driver_id, unique_drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分离出某些司机数据作为验证集\n",
    "def train_val_split(driver_val, driver_id, X, y):\n",
    "    val = []\n",
    "    tra = [a for a in range(len(X))]\n",
    "    assert (len(driver_id) == len(X)) & (len(driver_id) == len(y))\n",
    "    \n",
    "    for a in range(len(X)):\n",
    "        if driver_id[a] in driver_val:\n",
    "            val.append(a)\n",
    "    X_val = np.array([X[a] for a in val], dtype='float32')\n",
    "    y_val = np.array([y[a] for a in val], dtype='float32')\n",
    "    \n",
    "    for a in val:\n",
    "        tra.remove(a)\n",
    "    X_train = np.array([X[a] for a in tra], dtype='float32')\n",
    "    y_train = np.array([y[a] for a in tra], dtype='float32')\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以ndarray形式加载测试集\n",
    "def load_test(img_rows=224, img_cols=224):\n",
    "    print('Read test images')\n",
    "    path = os.path.join('.', 'test', '*.jpg')\n",
    "    files = glob.glob(path)\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    total = 0\n",
    "    thr = math.floor(len(files)/10)\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im(fl, img_rows, img_cols)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase)\n",
    "        total += 1\n",
    "        if total % thr == 0:\n",
    "            print('Read {} images from {}'.format(total, len(files)))\n",
    "\n",
    "    return X_test, X_test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_data(data, path):\n",
    "    if not os.path.isdir('cache'):\n",
    "        os.mkdir('cache')\n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file)\n",
    "        file.close()\n",
    "    else:\n",
    "        print('Directory doesnt exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        print('Restore data from pickle........')\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_and_val_data(img_rows, img_cols):\n",
    "\n",
    "    cache_path = os.path.join('cache', 'train_r_' + str(img_rows) +\n",
    "                              '_c_' + str(img_cols) + '_t_' +\n",
    "                              str(3) + '.dat')\n",
    "\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        X_train, y_train, driver_id, unique_drivers = load_train(img_rows, img_cols)\n",
    "        cache_data((X_train, y_train, driver_id, unique_drivers), cache_path)\n",
    "    else:\n",
    "        print('Restore train from cache!')\n",
    "        (X_train, y_train, driver_id, unique_drivers) = restore_data(cache_path)\n",
    "    driver_val = ['p026','p035','p039','p041']\n",
    "    X_train, y_train, X_val, y_val = train_val_split(driver_val, driver_id, X_train, y_train)\n",
    "    print('Train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数据随机排序并划分batch\n",
    "def shuffle_and_batch(batch_size, X_train, y_train):\n",
    "    new_X_train, new_y_train = utils.shuffle(X_train, y_train)\n",
    "    for start in range(0, len(new_X_train), batch_size):\n",
    "        end = min(start + batch_size, len(X_train))\n",
    "        yield np.array(new_X_train[start:end], dtype='float32'), np.array(new_y_train[start: end], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_model():\n",
    "    base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    predictions = Dense(10, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read drivers data\n",
      "Read train images\n",
      "Load folder c0\n",
      "Load folder c1\n",
      "Load folder c2\n",
      "Load folder c3\n",
      "Load folder c4\n",
      "Load folder c5\n",
      "Load folder c6\n",
      "Load folder c7\n",
      "Load folder c8\n",
      "Load folder c9\n",
      "Unique drivers: 26\n",
      "['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, driver_id, unique_drivers = load_train(224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_val = ['p026','p035','p039','p041']\n",
    "X_train, y_train, X_val, y_val = train_val_split(driver_val, driver_id, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19124, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 block5_pool\n",
      "19 flatten_1\n",
      "20 dense_1\n",
      "21 dense_2\n",
      "22 dense_3\n"
     ]
    }
   ],
   "source": [
    "sgd = optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "vgg = vgg_model()\n",
    "for layer in vgg.layers[:4]:\n",
    "    layer.trainable = True\n",
    "for layer in vgg.layers[4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "for i, layer in enumerate(vgg.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19124 samples, validate on 3300 samples\n",
      "Epoch 1/10\n",
      " 6976/19124 [=========>....................] - ETA: 6:53 - loss: 14.3713 - acc: 0.1075"
     ]
    }
   ],
   "source": [
    "hist = vgg.fit(x=X_train, y=y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_val, y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 64\n",
    "#steps_per_epoch = int(math.ceil(len(X_train)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist = vgg.fit_generator(shuffle_and_batch(batch_size, X_train, y_train), steps_per_epoch, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "import pydot\n",
    "import graphviz\n",
    "plot_model(vgg, show_shapes=True, to_file='model_simple.png')\n",
    "SVG(model_to_dot(vgg, show_shapes=True).create(prog='dot', format='svg'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
